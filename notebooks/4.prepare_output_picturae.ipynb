{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process output Picturae\n",
    "This notebook processes the output by Picturae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_description(x):\n",
    "    return pd.json_normalize(json.loads(x)).iloc[:, 1:2].values[0][0]\n",
    "\n",
    "\n",
    "def fix_labels(x):\n",
    "    return x.lower().replace(' ','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../data/intermediary/annotations_step3/'\n",
    "predicted_labels = pd.read_json('../output/predictions/20220630predictions.json', lines=True) #predictions before check by annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = []\n",
    "top_5 = []\n",
    "for k, v in predicted_labels['predictions'].to_dict().items():\n",
    "    top_1.append(list(v.keys())[-1])\n",
    "    top_5.append(list(v.keys()))\n",
    "\n",
    "\n",
    "predicted_labels['top_1'] = top_1\n",
    "predicted_labels['top_5'] = top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images\n",
    "id = image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_images.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexeer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexeer_data = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_indexeer_data.csv'))\n",
    "indexeer_data['annotated_label'] = indexeer_data['descriptions'].apply(process_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probleem gevallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "probleem_gevallen = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_probleemgevallen.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probleem gevallen lijkt niet relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_scans.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scans Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scans_images = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_scans_images.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## opmerkingen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opmerkingen = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_opmerkingen.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "controle_data = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_controle_data.csv'))\n",
    "controle_data['corrected_label'] = controle_data['descriptions'].apply(process_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scan acties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjwever/.local/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "scan_acties = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_scan_acties.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pad</th>\n",
       "      <th>naam</th>\n",
       "      <th>titel</th>\n",
       "      <th>formulier_id</th>\n",
       "      <th>status</th>\n",
       "      <th>completed_on</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_1</td>\n",
       "      <td>random_batch2_1</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "      <td>2022-03-28 12:30:50</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_10</td>\n",
       "      <td>random_batch2_10</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "      <td>2022-03-28 12:32:03</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_11</td>\n",
       "      <td>random_batch2_11</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "      <td>2022-03-28 12:33:27</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_12</td>\n",
       "      <td>random_batch2_12</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "      <td>2022-03-28 12:34:54</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_13</td>\n",
       "      <td>random_batch2_13</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "      <td>2022-03-28 12:36:12</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_14</td>\n",
       "      <td>random_batch2_14</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "      <td>2022-03-28 12:37:19</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_15</td>\n",
       "      <td>random_batch2_15</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "      <td>2022-03-28 12:38:26</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_16</td>\n",
       "      <td>random_batch2_16</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "      <td>2022-03-28 12:39:34</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_17</td>\n",
       "      <td>random_batch2_17</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "      <td>2022-03-28 12:40:45</td>\n",
       "      <td>2022-05-16 11:53:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>random_batch2_18</td>\n",
       "      <td>random_batch2_18</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "      <td>2022-03-28 12:42:10</td>\n",
       "      <td>2022-05-09 09:33:41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  pad              naam             titel  formulier_id  status  \\\n",
       "20  21  NaN   random_batch2_1   random_batch2_1             1     103   \n",
       "21  22  NaN  random_batch2_10  random_batch2_10             1     103   \n",
       "22  23  NaN  random_batch2_11  random_batch2_11             1     103   \n",
       "23  24  NaN  random_batch2_12  random_batch2_12             1     103   \n",
       "24  25  NaN  random_batch2_13  random_batch2_13             1     103   \n",
       "25  26  NaN  random_batch2_14  random_batch2_14             1     103   \n",
       "26  27  NaN  random_batch2_15  random_batch2_15             1     103   \n",
       "27  28  NaN  random_batch2_16  random_batch2_16             1     103   \n",
       "28  29  NaN  random_batch2_17  random_batch2_17             1     103   \n",
       "29  30  NaN  random_batch2_18  random_batch2_18             1     103   \n",
       "\n",
       "           completed_on           created_at           updated_at  \n",
       "20  2022-05-09 09:33:41  2022-03-28 12:30:50  2022-05-09 09:33:41  \n",
       "21  2022-05-09 09:33:41  2022-03-28 12:32:03  2022-05-09 09:33:41  \n",
       "22  2022-05-09 09:33:41  2022-03-28 12:33:27  2022-05-09 09:33:41  \n",
       "23  2022-05-16 11:53:15  2022-03-28 12:34:54  2022-05-16 11:53:15  \n",
       "24  2022-05-16 11:53:15  2022-03-28 12:36:12  2022-05-16 11:53:15  \n",
       "25  2022-05-09 09:33:41  2022-03-28 12:37:19  2022-05-09 09:33:41  \n",
       "26  2022-05-09 09:33:41  2022-03-28 12:38:26  2022-05-09 09:33:41  \n",
       "27  2022-05-16 11:53:15  2022-03-28 12:39:34  2022-05-16 11:53:15  \n",
       "28  2022-05-16 11:53:15  2022-03-28 12:40:45  2022-05-16 11:53:15  \n",
       "29  2022-05-09 09:33:41  2022-03-28 12:42:10  2022-05-09 09:33:41  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series = pd.read_csv(os.path.join(input_path, 'pic_vh_nl_prod_ranh_tagcorrection_deboer_table_series.csv'))\n",
    "series[series['titel'].str.contains('batch2')].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on when series where completed. \n",
    "Perhaps relevant when filtering on annotation step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MERGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24406\n",
      "24406\n",
      "32939\n"
     ]
    }
   ],
   "source": [
    "df = pd.merge(predicted_labels[['filename', 'predictions', 'top_1', 'top_5']], images[['title', 'id']], left_on='filename', right_on='title', how='left')\n",
    "print(df.shape[0])\n",
    "df.rename(columns = {'id':'image_id'}, inplace = True)\n",
    "\n",
    "df.drop(['filename'], axis=1, inplace=True)\n",
    "\n",
    "df = pd.merge(df, scans[['title','id', 'too_difficult', 'unusable']])\n",
    "print(df.shape[0])\n",
    "df.rename(columns = {'id':'scan_id'}, inplace = True)\n",
    "\n",
    "df = pd.merge(df, indexeer_data[['image_id', 'updated_at', 'gebruiker_id', 'annotated_label']])\n",
    "print(df.shape[0])\n",
    "df.rename(columns = {'updated_at':'annotated_on', 'gebruiker_id': 'annotator_id'}, inplace = True)\n",
    "\n",
    "df = pd.merge(df, controle_data[['image_id', 'updated_at', 'gebruiker_id', 'corrected_label']], on='image_id')\n",
    "df.rename(columns = {'updated_at':'checked_on', 'gebruiker_id': 'validator_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annotated_label'] = df['annotated_label'].apply(fix_labels)\n",
    "df['corrected_label'] = df['corrected_label'].apply(fix_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, opmerkingen[['scan_id', 'toelichting', 'gebruiker_id']], left_on='scan_id', right_on='scan_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Disagreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "disagreement = {}\n",
    "for i, group in df.groupby('image_id'):\n",
    "    if group['annotated_label'].values[0] != group['annotated_label'].values[1]:\n",
    "        disagreement[group['image_id'].values[0]] = 'disagree'\n",
    "    else:\n",
    "        disagreement[group['image_id'].values[0]] = 'agree'\n",
    "\n",
    "disagree_df = pd.DataFrame(disagreement, index=['agreement']).T\n",
    "df = pd.merge(df, disagree_df, left_on='image_id', right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if label appeared in top-1 or top-5 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_top_1 = []\n",
    "in_top_5 = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if row['corrected_label'] == row['top_1']:\n",
    "        in_top_1.append(1)\n",
    "        in_top_5.append(1)\n",
    "    elif row['corrected_label'] in row['top_5']:\n",
    "        in_top_1.append(0)\n",
    "        in_top_5.append(1)\n",
    "    else:\n",
    "        in_top_1.append(0)\n",
    "        in_top_5.append(0)\n",
    "\n",
    "df['in_top_1'] = in_top_1\n",
    "df['in_top_5'] = in_top_5\n",
    "\n",
    "df[(df['corrected_label'] == 'no_description_found') & (df['toelichting'].notnull())].drop_duplicates(subset=['title']).to_csv('no_desc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('output_step3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = glob.glob('../../data/step3/**/*.jpg') ##change accordingly\n",
    "export_path = '../data/step3_training_data/'\n",
    "\n",
    "if not os.path.exists(export_path):\n",
    "    os.makedirs(export_path)\n",
    "    print(\"created folder : \", export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in data_path:\n",
    "    filename = os.path.basename(_)[:-4]\n",
    "    try:\n",
    "        \n",
    "        label = df[df['title'] == filename]['corrected_label'].values[0]\n",
    "        path = os.path.join(export_path, label)\n",
    "        if os.path.isdir(path):\n",
    "            shutil.copy(_, path)\n",
    "        else:\n",
    "            os.mkdir(path)\n",
    "            shutil.copy(_, path)\n",
    "    except:\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export overview of no description found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['corrected_label'] == 'no_description_found'].to_csv('no_desc_step3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('hisvis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "87fc510cc897bc545846a47445e229a3c7c19d2613c167ce6a85f0f229feba93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
